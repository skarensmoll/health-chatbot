<html lang="en-us">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Web dictaphone</title>
<link href="https://fonts.googleapis.com/css?family=Roboto:100,300,400,500,700,900" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/@mdi/font@6.x/css/materialdesignicons.min.css" rel="stylesheet">
<link href="https://cdn.jsdelivr.net/npm/vuetify@2.x/dist/vuetify.min.css" rel="stylesheet">
<style>
  .ele {
    margin-bottom: 40px !important;
    margin-top: 40px !important;
  }

  .mainApp {
    background-color: #fcfcfc !important;
    margin-top: 40px !important;
  }
</style>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no, minimal-ui">
<link href="scripts/app.js" rel="stylesheet" type="text/css">
</head>

<body>
  <div id="app">
    <v-app class="mainApp">
      <v-main>
        <v-row justify="center">
          <v-col cols=11>
            <v-divider inset></v-divider>
            <v-card class="wrapper">
              <v-app-bar color="blue darken-2" dark>
                <v-avatar class="ele">
                  <img src="assets/bot.jpg" alt="bot" size="780">
                </v-avatar>
                <v-spacer></v-spacer>
                Status: <span v-if="recordingKey">Listening</span><span v-if="!recordingKey">Online</span>
                <v-icon large color="red darken-2" v-if="recordingKey">
                  mdi-Adjust
                </v-icon>
                <v-icon large color="green darken-2" v-if="!recordingKey">
                  mdi-Brightness-1
                </v-icon>

              </v-app-bar>
              <v-card-title>
                <h1>Baymax </h1>
              </v-card-title>
              <v-card-subtitle>
                Your Virtual Assistant
              </v-card-subtitle>

              <section class="sound-clips"></section>
              <audio id="audio">
              </audio>
            </v-card>
            <v-card class="responses">
              <span id="bot-response"></span>
            </v-card>
          </v-col>
          <v-col cols=11 style="position: absolute; bottom: 150;">
            <section class="main-controls">
              <canvas class="visualizer" height="60px" width="1000"></canvas>
            </section>
          </v-col>
        </v-row>
      </v-main>
    </v-app>
  </div>


  <script src="https://cdn.jsdelivr.net/npm/vue@2.x/dist/vue.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/vuetify@2.x/dist/vuetify.js"></script>
  <script>
    new Vue({
      el: '#app',
      vuetify: new Vuetify(),
      data() {
        return {
          dialog: false,
          recordingKey: false,
          // set up basic variables for app
          soundClips: document.querySelector(".sound-clips"),
          canvas: document.querySelector(".visualizer"),
          mainSection: document.querySelector(".main-controls"),
          BASE: "http://localhost:5000",
          canvasCtx: null,
          // disable stop button while not recording
        }
      },
      mounted() {
        var recording = false;
        window.addEventListener('keydown', (e) => {
          this.recordingKey = !this.recordingKey;
          if (e.key == 'f') {
            recording = this.recordingKey
            if (recording) {
              toRecord();
            } else {
              toStop();
            }
          }
        });
        /*CODE FROM JS DIRECTLY*/
        // set up basic variables for app

        const soundClips = document.querySelector(".sound-clips");
        const canvas = document.querySelector(".visualizer");
        const mainSection = document.querySelector(".main-controls");

        // disable stop button while not recording
        const BASE = "http://localhost:5000";

        // visualiser setup - create web audio api context and canvas

        let audioCtx;
        const canvasCtx = canvas.getContext("2d");

        //main block for doing the audio recording

        if (navigator.mediaDevices.getUserMedia) {
          console.log("getUserMedia supported.");

          const constraints = { audio: true };
          let chunks = [];

          let onSuccess = function (stream) {
            const mediaRecorder = new MediaRecorder(stream);
            var currentRecording = false;
            visualize(stream);
            window.addEventListener('keydown', (e) => {
              currentRecording = !currentRecording;
              if (e.key == 'g') {
                if (currentRecording) {
                  toRecord(mediaRecorder);
                } else {
                  toStop(mediaRecorder);
                }
              }
            });

            mediaRecorder.onstop = function (e) {
              console.log("data available after MediaRecorder.stop() called.");

              const audio = document.createElement("audio");

              audio.controls = true;
              const blob = new Blob(chunks, { type: "audio/ogg; codecs=opus" });
              var reader = new FileReader();
              reader.readAsDataURL(blob);

              reader.onloadend = function () {
                var base64String = reader.result;
                const resultFormatted = base64String
                  .substr(base64String.indexOf(", ") + 1)
                  .replace("data:audio/ogg; codecs=opus;base64,", "");
                const bodyFormat = JSON.stringify({
                  record: resultFormatted,
                  sessionId: "19b3ee27-2fac-4ab2-ac0f-c377b2348cf8",
                });
                console.log(bodyFormat);

                fetch(`${BASE}/resolve-query`, {
                  method: "POST",
                  headers: {
                    "Content-Type": "application/json",
                  },
                  body: bodyFormat,
                })
                  .then((response) => response.json())
                  .then(({ data }) => {
                    document.getElementById("bot-response").innerHTML = data;
                    readOutLoud(data);
                  })
                  .catch((error) => {
                    console.error("Error:", error);
                  });
              };

              chunks = [];
              const audioURL = window.URL.createObjectURL(blob);
              audio.src = audioURL;
              console.log("recorder stopped");
            };

            mediaRecorder.ondataavailable = function (e) {
              chunks.push(e.data);
            };
          };

          let onError = function (err) {
            console.log("The following error occured: " + err);
          };

          navigator.mediaDevices.getUserMedia(constraints).then(onSuccess, onError);
        } else {
          console.log("getUserMedia not supported on your browser!");
        }

        const readOutLoud = (text) => {
          fetch(`${BASE}/audio`, {
            body: JSON.stringify({ text }),
            cache: "no-cache",
            headers: {
              "Content-Type": "application/json",
            },
            method: "POST",
          })
            .then((response) => {
              return response.blob();
            })
            .then((blob) => {
              var url = URL.createObjectURL(blob);
              var audioElement = document.getElementById("audio");
              audioElement.src = url;
              audioElement.play();
            });
        };

        function visualize(stream) {
          if (!audioCtx) {
            audioCtx = new AudioContext();
          }

          const source = audioCtx.createMediaStreamSource(stream);

          const analyser = audioCtx.createAnalyser();
          analyser.fftSize = 2048;
          const bufferLength = analyser.frequencyBinCount;
          const dataArray = new Uint8Array(bufferLength);

          source.connect(analyser);
          //analyser.connect(audioCtx.destination);

          draw();

          function draw() {
            const WIDTH = canvas.width;
            const HEIGHT = canvas.height;

            requestAnimationFrame(draw);

            analyser.getByteTimeDomainData(dataArray);

            canvasCtx.fillStyle = "rgb(255, 255, 255)";
            canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = "rgb(42, 169, 178)";

            canvasCtx.beginPath();

            let sliceWidth = (WIDTH * 1.0) / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
              let v = dataArray[i] / 128.0;
              let y = (v * HEIGHT) / 2;

              if (i === 0) {
                canvasCtx.moveTo(x, y);
              } else {
                canvasCtx.lineTo(x, y);
              }

              x += sliceWidth;
            }

            canvasCtx.lineTo(canvas.width, canvas.height / 2);
            canvasCtx.stroke();
          }
        }

        function toRecord(m) {
          m.start();
        }

        function toStop(m) {
          m.stop();
        }
        window.onresize = function () {
          canvas.width = mainSection.offsetWidth;
        };

        window.onresize();
        /*END CODE FROM JS DIRECTLY*/
      }
    })
  </script>
</body>

</html>